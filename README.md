# Transformer-Potential: A Neural Network Interaction Potential using Transformer Encoder

<!-- Add an image in the header -->
<!-- ![Model Workflow](./New_Model.png) -->
<!-- ![Model Workflow](./New_Model.png)
 -->

<img src="./New_Model.png" alt="Model Workflow" width="800" height="300"/>

This reserach proposed an efficient ML potential for molecular energy prediction.

## Table of Contents

- [Requirements](#Requirements)
- [Installation](#installation)
- [Citation](#Citation)
- [License](#license)


## Requirements

The following packages are required to work and run the project files.

- [pytorch-1.1](#pytorch-1.1)
- [numpy](#numpy)
- [ase](#ase)
- [Pandas](#Pandas)
- [h5py](#h5py)
- [ypstruct](#ypstruct)



## Installation

Please use the following steps for running and installation of the project files.

```bash
# Example installation steps
$ cd Transformer-Potential
$ git clone https://github.com/OmidTarkhaneh/TransformerPotential.git
$ Run the Main.py
```

## Citation
To use this project please cite the following references:

## License

